{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease\n",
    "El conjunto de datos \"Heart Disease\" contiene información médica sobre pacientes que se sometieron a pruebas para detectar enfermedades cardíacas. Estos datos fueron recopilados en un estudio realizado en el Instituto de Aprendizaje Automático de la Universidad de California, Irvine (UCI).\n",
    "\n",
    "Atributos:\n",
    "<ul>\n",
    "<li>age: Edad del paciente (numérico).</li>\n",
    "<li>sex: Género del paciente (0 = mujer, 1 = hombre).</li>\n",
    "<li>cp: Tipo de dolor en el pecho (0 = típico angina, 1 = angina atípica, 2 = dolor no anginal, 3 = asintomático).</li>\n",
    "<li>trestbps: Presión arterial en reposo (en mm Hg) (numérico).</li>\n",
    "<li>chol: Colesterol sérico en mg/dl (numérico).</li>\n",
    "<li>fbs: Nivel de azúcar en sangre en ayunas > 120 mg/dl (0 = falso, 1 = verdadero).</li>\n",
    "<li>restecg: Resultados electrocardiográficos en reposo (0 = normal, 1 = con anormalidad de la onda ST-T, 2 = hipertrofia ventricular izquierda probable o definitiva).</li>\n",
    "<li>thalach: Frecuencia cardíaca máxima alcanzada (numérico).</li>\n",
    "<li>exang: Angina inducida por ejercicio (0 = no, 1 = sí).</li>\n",
    "<li>oldpeak: Depresión del segmento ST inducida por el ejercicio en relación con el descanso (numérico).</li>\n",
    "<li>slope: Pendiente del segmento ST de ejercicio máximo (0 = ascendente, 1 = plano, 2 = descendente).</li>\n",
    "<li>ca: Número de vasos principales (0-3) coloreados por fluoroscopia (numérico).</li>\n",
    "<li>thal: Enfermedad de Talasemia (3 = normal, 6 = defecto fijo, 7 = defecto reversible).</li>\n",
    "<li>target: clase objetivo. Presencia de enfermedad cardíaca (0 = no, 1 = sí).</li>\n",
    "</ul>\n",
    "\n",
    "Se puede obtener en https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos\n",
    "data = pd.read_csv(\"heart.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0      52    1   0       125   212    0        1      168      0      1.0  \\\n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar filas con valores nulos\n",
    "rows_with_nans = data[data.isnull().any(axis=1)]\n",
    "rows_with_nans\n",
    "\n",
    "# Reemplazar valores faltantes\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores diferentes en la clase 'target': [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los valores diferentes de la clase target\n",
    "unique_values = data['target'].unique()\n",
    "print(f\"Valores diferentes en la clase 'target': {unique_values}\")\n",
    "# Transformar la variable de salida (target) en binaria\n",
    "data['target'] = data['target'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de características y etiquetas\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "835   49    1   2       118   149    0        0      126      0      0.8  \\\n",
       "137   64    0   0       180   325    0        1      154      1      0.0   \n",
       "534   54    0   2       108   267    0        0      167      0      0.0   \n",
       "495   59    1   0       135   234    0        1      161      0      0.5   \n",
       "244   51    1   2       125   245    1        0      166      0      2.4   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "700   41    1   2       130   214    0        0      168      0      2.0   \n",
       "71    61    1   0       140   207    0        0      138      1      1.9   \n",
       "106   51    1   0       140   299    0        1      173      1      1.6   \n",
       "270   43    1   0       110   211    0        1      161      0      0.0   \n",
       "860   52    1   0       112   230    0        1      160      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "835      2   3     2  \n",
       "137      2   0     2  \n",
       "534      2   0     2  \n",
       "495      1   0     3  \n",
       "244      1   0     2  \n",
       "..     ...  ..   ...  \n",
       "700      1   0     2  \n",
       "71       2   1     3  \n",
       "106      2   0     3  \n",
       "270      2   0     3  \n",
       "860      2   1     2  \n",
       "\n",
       "[820 rows x 13 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antes de la tranformacion\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 13)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de variables numéricas y categóricas\n",
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Aplicar diferentes transformaciones a diferentes columnas de un DataFrame\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar los datos\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58584022, -0.77945357, -1.93503098, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.05147737,  2.74173173,  1.61063407, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.04006769, -1.34738668,  0.44217627, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.36753121,  0.46999928,  1.08684264, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.24076726, -1.23380006, -0.68598988, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.2583767 , -1.12021343, -0.30321922, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Despues de la transformacion\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener el número de características después del preprocesamiento. 30 porque aplica onehot\n",
    "input_shape = X_train.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el modelo\n",
    "# Sequential es la clase en Keras que permite crear un modelo secuencial, lo que significa que las capas del modelo se apilan una tras otra en un solo flujo lineal\n",
    "# Dense es una clase que representa una capa totalmente conectada\n",
    "# Units es el número de neuronas en la capa que es el primer parametro\n",
    "# Activation: la función de activación que se aplica a la salida de las neuronas en esta capa\n",
    "# -relu (Rectified Linear Unit): max(0, x). Es una función no lineal \n",
    "# -sigmoid: 1 / (1 + exp(-x)). Es útil para la salida de una red neuronal que realiza clasificación binaria, ya que transforma la salida en un valor entre 0 y 1.\n",
    "# -softmax': Específica para problemas de clasificación multiclase. Convierte las salidas en probabilidades que suman a 1.\n",
    "# -Para problemas de regresión, no se suele utilizar ninguna función de activación específica.\n",
    "# input_shape: La forma de los datos de entrada. Solo se especifica en la primera capa del modelo. Se especifica en forma de tupla\n",
    "# Se utilizan las potencias de 2 debido a las eficiencias computacionales que pueden brindar, especialmente en hardware moderno como GPUs.\n",
    "# Respecto a las funciones de activación, no es obligatorio utilizar la misma función de activación en todas las capas\n",
    "model = Sequential([\n",
    "    # Primera capa con 64 neuronas y activación ReLU\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),  \n",
    "    # Segunda capa con 32 neuronas y activación ReLU\n",
    "    Dense(32, activation='relu'), \n",
    "    # Capa de salida con activación Sigmoid para clasificación binaria\n",
    "    Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "#optimizer: especifica el algoritmo que se utilizará para ajustar los pesos del modelo durante el entrenamiento. Ejemplos comunes son adam, sgd, rmsprop\n",
    "# loss: es la función de pérdida que se utilizará para evaluar qué tan bien el modelo está realizando la tarea de aprendizaje. La función de pérdida calcula la diferencia entre las predicciones del modelo y las etiquetas reales. Se utiliza binary_crossentropy para problemas de clasificacion binaria\n",
    "# metrics: son las métricas que se evaluarán durante el entrenamiento y la evaluación del modelo. \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4097 (16.00 KB)\n",
      "Trainable params: 4097 (16.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 6ms/step - loss: 0.6083 - accuracy: 0.7439 - val_loss: 0.5728 - val_accuracy: 0.7622\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8049 - val_loss: 0.5002 - val_accuracy: 0.7866\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8460 - val_loss: 0.4398 - val_accuracy: 0.7927\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8506 - val_loss: 0.3949 - val_accuracy: 0.8354\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8735 - val_loss: 0.3695 - val_accuracy: 0.8537\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8872 - val_loss: 0.3538 - val_accuracy: 0.8598\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8918 - val_loss: 0.3466 - val_accuracy: 0.8537\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9040 - val_loss: 0.3490 - val_accuracy: 0.8476\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9177 - val_loss: 0.3477 - val_accuracy: 0.8476\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9177 - val_loss: 0.3495 - val_accuracy: 0.8537\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9268 - val_loss: 0.3515 - val_accuracy: 0.8659\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9329 - val_loss: 0.3512 - val_accuracy: 0.8659\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9345 - val_loss: 0.3529 - val_accuracy: 0.8841\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9421 - val_loss: 0.3519 - val_accuracy: 0.8720\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9482 - val_loss: 0.3590 - val_accuracy: 0.8720\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9512 - val_loss: 0.3546 - val_accuracy: 0.8720\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9497 - val_loss: 0.3542 - val_accuracy: 0.8720\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9527 - val_loss: 0.3499 - val_accuracy: 0.8720\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9588 - val_loss: 0.3533 - val_accuracy: 0.8902\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9543 - val_loss: 0.3495 - val_accuracy: 0.8720\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9573 - val_loss: 0.3509 - val_accuracy: 0.8902\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9604 - val_loss: 0.3482 - val_accuracy: 0.8963\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9649 - val_loss: 0.3476 - val_accuracy: 0.9085\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9649 - val_loss: 0.3469 - val_accuracy: 0.9024\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9710 - val_loss: 0.3415 - val_accuracy: 0.9024\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9756 - val_loss: 0.3490 - val_accuracy: 0.8963\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9741 - val_loss: 0.3399 - val_accuracy: 0.9024\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9771 - val_loss: 0.3300 - val_accuracy: 0.8780\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9771 - val_loss: 0.3510 - val_accuracy: 0.9207\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9787 - val_loss: 0.3340 - val_accuracy: 0.9146\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.3400 - val_accuracy: 0.9207\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9802 - val_loss: 0.3423 - val_accuracy: 0.9207\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9832 - val_loss: 0.3393 - val_accuracy: 0.9085\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9832 - val_loss: 0.3486 - val_accuracy: 0.9207\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9863 - val_loss: 0.3222 - val_accuracy: 0.9085\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.3383 - val_accuracy: 0.9207\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.3296 - val_accuracy: 0.9207\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.3478 - val_accuracy: 0.9207\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9909 - val_loss: 0.3427 - val_accuracy: 0.9207\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9909 - val_loss: 0.3349 - val_accuracy: 0.9207\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9939 - val_loss: 0.3327 - val_accuracy: 0.9268\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9970 - val_loss: 0.3335 - val_accuracy: 0.9268\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9970 - val_loss: 0.3527 - val_accuracy: 0.9268\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9970 - val_loss: 0.3531 - val_accuracy: 0.9268\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9985 - val_loss: 0.3536 - val_accuracy: 0.9268\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9985 - val_loss: 0.3608 - val_accuracy: 0.9268\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9985 - val_loss: 0.3468 - val_accuracy: 0.9268\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9985 - val_loss: 0.3483 - val_accuracy: 0.9268\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9985 - val_loss: 0.3586 - val_accuracy: 0.9268\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.3652 - val_accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "# epochs: define el número de veces que el algoritmo de entrenamiento recorrerá todo el conjunto de datos de entrenamiento. Cada pasada completa del conjunto de datos se llama una \"época\". \n",
    "# batch_size: define el número de muestras que se procesarán antes de actualizar los parámetros del modelo.\n",
    "# validation_split: es la fracción del conjunto de datos de entrenamiento que se reservará para validar el modelo durante el entrenamiento. Este conjunto de datos de validación se utiliza para evaluar el rendimiento del modelo en datos no vistos durante el entrenamiento\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9512\n",
      "Test Accuracy: 0.9512194991111755\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con más capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 6ms/step - loss: 0.6852 - accuracy: 0.4878 - val_loss: 0.6691 - val_accuracy: 0.4756\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.5503 - val_loss: 0.6278 - val_accuracy: 0.5732\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7546 - val_loss: 0.5657 - val_accuracy: 0.7378\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8506 - val_loss: 0.5317 - val_accuracy: 0.7988\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8537 - val_loss: 0.5126 - val_accuracy: 0.8841\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8902 - val_loss: 0.5047 - val_accuracy: 0.8537\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.9207 - val_loss: 0.5004 - val_accuracy: 0.8720\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.9375 - val_loss: 0.4986 - val_accuracy: 0.8598\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.9223 - val_loss: 0.4911 - val_accuracy: 0.8902\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.9421 - val_loss: 0.4846 - val_accuracy: 0.8963\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.9512 - val_loss: 0.4863 - val_accuracy: 0.8841\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.9527 - val_loss: 0.4697 - val_accuracy: 0.8963\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.9527 - val_loss: 0.4534 - val_accuracy: 0.8902\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.9527 - val_loss: 0.4373 - val_accuracy: 0.8902\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9573 - val_loss: 0.3982 - val_accuracy: 0.8963\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9588 - val_loss: 0.3659 - val_accuracy: 0.8841\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9619 - val_loss: 0.3680 - val_accuracy: 0.8963\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9680 - val_loss: 0.4093 - val_accuracy: 0.8963\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9695 - val_loss: 0.4276 - val_accuracy: 0.9024\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9726 - val_loss: 0.4354 - val_accuracy: 0.8963\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9726 - val_loss: 0.4181 - val_accuracy: 0.8963\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9726 - val_loss: 0.4022 - val_accuracy: 0.8963\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9726 - val_loss: 0.4195 - val_accuracy: 0.9085\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9741 - val_loss: 0.4088 - val_accuracy: 0.9085\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9771 - val_loss: 0.3944 - val_accuracy: 0.9085\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9771 - val_loss: 0.4025 - val_accuracy: 0.9085\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9771 - val_loss: 0.3888 - val_accuracy: 0.9207\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9756 - val_loss: 0.3869 - val_accuracy: 0.9329\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 0.4641 - val_accuracy: 0.9207\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.4688 - val_accuracy: 0.9329\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9771 - val_loss: 0.4362 - val_accuracy: 0.9207\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9802 - val_loss: 0.4389 - val_accuracy: 0.9329\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.4506 - val_accuracy: 0.9390\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.4454 - val_accuracy: 0.9390\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9924 - val_loss: 0.4496 - val_accuracy: 0.9390\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9924 - val_loss: 0.4405 - val_accuracy: 0.9390\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.4555 - val_accuracy: 0.9390\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.4948 - val_accuracy: 0.9390\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.5705 - val_accuracy: 0.9390\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.5065 - val_accuracy: 0.9390\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9985 - val_loss: 0.5255 - val_accuracy: 0.9390\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.5308 - val_accuracy: 0.9390\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.5371 - val_accuracy: 0.9390\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.5362 - val_accuracy: 0.9390\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.5489 - val_accuracy: 0.9390\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.5464 - val_accuracy: 0.9390\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.5642 - val_accuracy: 0.9390\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.5667 - val_accuracy: 0.9390\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.5399 - val_accuracy: 0.9390\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.5811 - val_accuracy: 0.9390\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.9561\n",
      "Test Accuracy: 0.9560975432395935\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con parámetros de kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial\n",
    "# kernel_initializer: Este parámetro especifica el método para inicializar los pesos de la red neuronal. Valores comunes son 'glorot_uniform', 'he_normal',\n",
    "# kernel_regularizer: Se utiliza para aplicar penalizaciones a los pesos de la red neuronal durante el entrenamiento\n",
    "# dropout: Esta capa se puede agregar entre capas densas para ayudar a prevenir el sobreajuste. dropout apaga aleatoriamente un porcentaje de unidades (neuronas) durante el entrenamiento\n",
    "model = Sequential([\n",
    "    # para aplicar una regularización L2 a los pesos de la primera capa densa\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,), kernel_regularizer=regularizers.l2(0.01)), \n",
    "    # Se agrega una capa de Dropout con una tasa del 50% para ayudar a prevenir el sobreajuste\n",
    "    Dropout(0.5), \n",
    "    # para inicializar los pesos de la segunda capa densa con el método 'he_normal'\n",
    "    Dense(32, activation='relu', kernel_initializer='he_normal'), \n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "# Compilamos el modelo con el optimizador RMSprop, la función de pérdida mean_squared_error, y la métrica AUC.\n",
    "model.compile(optimizer=RMSprop(), loss='mean_squared_error', metrics=[AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_auc = model.evaluate(X_test, y_test)\n",
    "print(f'Test AUC: {test_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con parámetros de bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial\n",
    "# bias_initializer: Similar a kernel_initializer, este parámetro especifica el método para inicializar los sesgos de la red neuronal.\n",
    "# bias_regularizer: Similar a kernel_regularizer, pero se aplica a los sesgos de la red neuronal.\n",
    "# activity_regularizer: Se utiliza para aplicar penalizaciones a la actividad de las neuronas de la red neuronal durante el entrenamiento.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,),\n",
    "          kernel_regularizer=regularizers.l2(0.01),\n",
    "          # bias_initializer para inicializar los sesgos de las capas densas. En la primera capa, los sesgos se inicializan como ceros\n",
    "          bias_initializer='zeros', \n",
    "          # bias_regularizer para aplicar una regularización L2 a los sesgos de las capas densas. Se aplica regularización L2 con un factor de penalización de 0.01 en ambas capas.\n",
    "          bias_regularizer=regularizers.l2(0.01),\n",
    "          # activity_regularizer para aplicar una regularización L2 a la actividad de las neuronas en las capas densas. También se aplica regularización L2 con un factor de penalización de 0.01 en ambas capas.\n",
    "          activity_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_initializer='he_normal',\n",
    "          bias_initializer='ones', # en la segunda capa se inicializan como unos\n",
    "          bias_regularizer=regularizers.l2(0.01),\n",
    "          activity_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con más capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial\n",
    "# BatchNormalization normaliza la activación de cada neurona en la capa anterior, lo que ayuda a estabilizar y acelerar el proceso de entrenamiento.\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_shape,),\n",
    "          kernel_regularizer=regularizers.l2(0.01),\n",
    "          bias_initializer='zeros',\n",
    "          bias_regularizer=regularizers.l2(0.01),\n",
    "          activity_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', kernel_initializer='he_normal',\n",
    "          bias_initializer='ones',\n",
    "          bias_regularizer=regularizers.l2(0.01),\n",
    "          activity_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu',\n",
    "          kernel_regularizer=regularizers.l2(0.01),\n",
    "          bias_initializer='zeros',\n",
    "          bias_regularizer=regularizers.l2(0.01),\n",
    "          activity_regularizer=regularizers.l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el optimizador con una tasa de aprendizaje específica\n",
    "# Tasa de Aprendizaje (Learning Rate): Controla la magnitud de las actualizaciones de los pesos durante el entrenamiento\n",
    "optimizer = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la arquitectura de la red neuronal\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir callbacks\n",
    "# Callbacks: Funciones que se llaman en ciertos puntos durante el entrenamiento, como al final de cada época. Pueden ser útiles para realizar tareas como el almacenamiento de checkpoints, el ajuste dinámico de la tasa de aprendizaje, etc.\n",
    "# EarlyStopping para detener el entrenamiento si la pérdida en el conjunto de validación deja de disminuir después de cierto número de épocas (patience), y ModelCheckpoint para guardar el modelo con la menor pérdida en el conjunto de validación durante el entrenamiento.\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura del modelo\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar lista para almacenar resultados de precisión\n",
    "accuracy_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar validación cruzada\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Crear y compilar el modelo\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Evaluar el modelo en los datos de prueba\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión media de la validación cruzada\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(f'Accuracy (Cross-Validation): {mean_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
