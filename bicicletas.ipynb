{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Bike renting dataset\n","El conjunto de datos de alquiler de bicicletas por dias incluye registros detallados del uso compartido de bicicletas en una ciudad, con cada registro representando un dia específico. Las características del dataset son:\n","\n","\n","\n","<ul>\n","<li>dteday: Marca temporal que indica la fecha.\n","<li>season: Estación del año (1: invierno, 2: primavera, 3: verano, 4: otoño).\n","<li>yr: Año de la observación (por ejemplo, 0: 2011, 1: 2012).\n","<li>mnth: Mes del año (1 a 12).\n","<li>holiday: Indicador de si el día es festivo (0: no festivo, 1: festivo).\n","<li>weekday: Día de la semana (0: domingo, 1: lunes, ..., 6: sábado).\n","<li>workingday: Indicador de si es un día laboral (0: fin de semana o festivo, 1: día laboral).\n","<li>weathersit: Estado del clima (1: despejado, 2: nublado, 3: lluvia ligera, 4: lluvia fuerte).\n","<li>temp: Temperatura normalizada en grados Celsius.\n","<li>atemp: Sensación térmica normalizada en grados Celsius.\n","<li>hum: Humedad relativa normalizada.\n","<li>windspeed: Velocidad del viento normalizada.\n","<li>casual: Número de usuarios casuales que alquilan bicicletas sin suscripción.\n","<li>registered: Número de usuarios registrados que alquilan bicicletas con suscripción.\n","<li>cnt: Número total de bicicletas alquiladas en esa hora (suma de usuarios casuales y registrados).\n","</ul>\n","\n","Se puede descargar el conjunto de datos en https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716478115797,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"2kcvoUSXkccu"},"outputs":[],"source":["import sys\n","import pandas as pd\n","from pandas import read_csv\n","import numpy\n","from numpy import array\n","import matplotlib.pyplot as plt\n","import math\n","import tensorflow\n","import keras\n","import sklearn\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from google.colab import drive\n","import os\n","from contextlib import nullcontext\n","\n","\n","# Variables iniciales\n","Historia=1\n","BATCHSIZE=1\n","EPOCAS=1\n","LSTM_DIM=1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716477430536,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"08B9RzzOkccx","outputId":"e088c0e3-c35c-465b-e115-aef7955a2e79"},"outputs":[],"source":["print (sys.version_info)\n","print (\"NumPy: \", numpy.__version__)\n","print (\"Pandas: \", pd.__version__)\n","print (\"TensorFlow: \", tensorflow.__version__)\n","print (\"Keras: \", keras.__version__)\n","print (\"SciKitLearn: \", sklearn.__version__)\n"]},{"cell_type":"markdown","metadata":{"id":"_-bk9s-Lkccy"},"source":["<h1>Carga del fichero</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24863,"status":"ok","timestamp":1716477458557,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"BLQXiqiTpvT4","outputId":"9cb68e85-b2e2-4357-99b5-56f94c71b6b7"},"outputs":[],"source":["drive.mount('/content/drive')\n","path = '/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/day.csv'\n","dfBikes=pd.read_csv (path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1716477479329,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"tG4JleYDp0Q3","outputId":"360ba8e2-abb3-436e-a141-96a571b5904d"},"outputs":[],"source":["# Ver nombres de la columnas\n","dfBikes.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716477483301,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"WeG7c2Jikccz","tags":[]},"outputs":[],"source":["# Renombramos las columnas\n","dfBikes.rename(columns = {'instant':'Id', 'dteday':'Fecha',\n","                     \"season\":'Estacion', 'yr':'Anio', 'mnth':'Mes',\n","                     'holiday':'Festivo','weekday':'DiaSemana','workingday':'DiaTrabajo','weathersit':'Tiempo','Temperatura':'temp','SensacionTemperatura':'atemp','Humedad':'hum','windspeed':'VelocidadViento','casual':'Casual','registered':'Registrado','cnt':'Cuenta'}, inplace=True)\n","\n","# Ordenamos por el id\n","dfBikes.sort_values(['Id'], inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716477488817,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"BNKze86ep2rX","outputId":"bb3cf7c7-5743-4924-a410-63f9376aa4d1"},"outputs":[],"source":["# Contar el número de valores nulos por columna\n","valores_nulos_por_columna = dfBikes.isnull().sum()\n","\n","# Mostrar el resultado\n","print(valores_nulos_por_columna)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":568,"status":"ok","timestamp":1716477504723,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"iwW18BLfpySP","outputId":"cd386e94-53ba-4817-eee5-1ecde82a0f56"},"outputs":[],"source":["# No es necesario porque no hay nulos\n","dfBikes.dropna(inplace=True)\n","dfBikes"]},{"cell_type":"markdown","metadata":{"id":"nKJ-xQffkcc0"},"source":["## Funciones"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716477601226,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"54YHI5TCkcc0","tags":[]},"outputs":[],"source":["# Convertir los datos en un formato adecuado para entrenar modelos de series temporales, en este caso LSTM\n","def CreaDatos(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        end_ix = i + n_steps\n","        if end_ix > len(sequence)-1:\n","            break\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","# Función para visualizar en un gráfico la predicción y el valor real\n","# Aquí se desnormalizan los datos. Para ello, se despeja la fórmula de normalización\n","def CalculoRMSE (titulo2):\n","    # En base al modelo establecido, se realizan predicciones y se desnormalizan los datos\n","    testPredict = model.predict(testX, batch_size=BATCHSIZE)*(MaxRealY - MinRealY) + MinRealY\n","    # Los valores reales se desnormalizan\n","    testReal=testY[:,13]*(MaxRealY - MinRealY) + MinRealY\n","\n","    # Se calcula el RMSe\n","    testScore = math.sqrt(mean_squared_error(testReal, testPredict.reshape(-1,1)))\n","\n","    # Se realiza el gráfico\n","    plt.plot (testPredict, label=\"Predict\")\n","    plt.plot (testReal, label=\"Real\")\n","    plt.legend ()\n","    plt.title (\"Prediccion de bicicletas alquiladas en el dia.\\n\"+titulo2+\" Historia=\"+str (Historia)+\" Epocas=\"+str (EPOCAS)+ \" LSTM_dim=\"+str (LSTM_DIM))\n","    plt.show()\n","    return testScore\n"]},{"cell_type":"markdown","metadata":{"id":"7_VovgMVkcc0"},"source":["<h1>Procesamiento de los datos</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1716477616397,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"RzIqnYKEkcc1","outputId":"924c1fb0-9939-460a-939f-a48be294e1c5"},"outputs":[],"source":["# Seleccionamos las columnas a utilizar. Todas menos la de la fecha y la del id\n","df = dfBikes.iloc[:,2:]\n","print(df)\n","print(df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1716477633564,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"_wZLo9s0kcc1","outputId":"4a9ed852-9be1-4503-be4c-6a85905502e6"},"outputs":[],"source":["# Buscamos el mayor y menor valor de la clase\n","MinRealY=df[\"Cuenta\"].min()\n","MaxRealY=df[\"Cuenta\"].max()\n","print(MinRealY)\n","print(MaxRealY)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1716477650140,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"um00oGSUkcc2","outputId":"626e2a08-2daf-4d6e-b701-6810caec606d"},"outputs":[],"source":["# Normalizamos los datos\n","scaler  = MinMaxScaler()\n","dataset = scaler.fit_transform(df)\n","print(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716477654033,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"RC3MjhGdkcc2"},"outputs":[],"source":["# Separamos en conjunto de entrenamiento y de test\n","train_size = int(len(df) * 0.67)\n","test_size  = len(df) - train_size\n","train = dataset[0:train_size,:]\n","test  = dataset[train_size:len(df),:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716477679476,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"HqzSjan1CsKg","outputId":"3419593b-bc49-4b55-b09a-0556f0b1a138"},"outputs":[],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1716478072018,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"rWSLCrx9D9T_","outputId":"99e534e5-528d-4096-d92e-9a60e15b2698"},"outputs":[],"source":["# Como se desnormaliza\n","desnomalizar=test[:,13]*(MaxRealY - MinRealY) + MinRealY\n","desnomalizar"]},{"cell_type":"markdown","metadata":{"id":"OGTiWL5Kkcc2"},"source":["<h1>MLP</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716477955874,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"k0Ko1yjAkcc3"},"outputs":[],"source":["from tensorflow.keras import datasets, layers, models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":329,"status":"ok","timestamp":1716477986049,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"_eKR6e9Kkcc3"},"outputs":[],"source":["# Preparar los datos separando la clase de los atributos utilizados para realizar las predicciones\n","trainX=train[:,0:12]\n","trainY=train[:,13]\n","testX=test[:,0:12]\n","testY=test[:,13]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":894,"status":"ok","timestamp":1716478109495,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"i1U-TxQ1EUWM"},"outputs":[],"source":["\n","# Dataframe para almacenar las combinaciones de parametros y su RMSE medio obtenido en las 3 iteraciones\n","dfError = pd.DataFrame(columns=[\"opt\",\"capas\",\"perdida\",\"batch\",\"epoca\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","optimizadores=[\"SGD\",\"adam\",\"RMSprop\"]\n","funciones_perdidas=[\"mean_squared_error\",\"mean_absolute_error\",\"huber_loss\"]\n","batch_sizes=[16,32,64]\n","epocas=[6,10,14]\n","capas=[1,3,5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1716478184544,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"Hux0unofEiPd","outputId":"7ca325fd-d094-438c-f72f-5beba2cd3be8"},"outputs":[],"source":["print(trainX.shape)\n","print(trainY.shape)\n","print(testX.shape)\n","print(testY.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1247,"status":"ok","timestamp":1716479056125,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"E8epQZS_FNW_"},"outputs":[],"source":["trainX_reduced=trainX[:50]\n","trainY_reduced=trainY[:50]\n","testX_reduced=testX[:20]\n","testY_reduced=testY[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716479059854,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"znnk5mIZHI3Y","outputId":"8892edf4-581c-46e2-f44a-5f44cfdadeef"},"outputs":[],"source":["print(trainX_reduced.shape)\n","print(trainY_reduced.shape)\n","print(testX_reduced.shape)\n","print(testY_reduced.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1698364,"status":"error","timestamp":1716481035706,"user":{"displayName":"chema tfg","userId":"03198431984494101568"},"user_tz":-120},"id":"KjNbSOFnkcc3","outputId":"a3f69b6a-dd34-40a1-9639-9eef1968bf83"},"outputs":[],"source":["\n","# Recorrer parámetros\n","for capas_ind in range(len(capas)):\n","  for perdida_ind in range(len(funciones_perdidas)):\n","    for batch_ind in range(len(batch_sizes)):\n","      for epoca_ind in range(len(epocas)):\n","        for opt_ind in range(len(optimizadores)):\n","\n","          # Imprimir parámetros que se evaluan\n","          print(\"\\n\\n\\n\")\n","          print(\"capas:\",str(capas_ind))\n","          print(\"perdida:\",str(perdida_ind))\n","          print(\"batch:\",str(batch_ind))\n","          print(\"epoca:\",str(epoca_ind))\n","          print(\"opt:\",str(opt_ind))\n","\n","          # Se establece el optimizador\n","          optimizer=None\n","          if(optimizadores[opt_ind]==\"SGD\"):\n","            optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n","            print(\"SGD\")\n","          if(optimizadores[opt_ind]==\"adam\"):\n","            optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","            print(\"Adam\")\n","          if(optimizadores[opt_ind]==\"RMSprop\"):\n","            optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n","            print(\"RMSprop\")\n","\n","          # Se establece el modelo\n","          modelNN_Keras = models.Sequential()\n","          # Aquí input_dim es trainX.shape[1] que es 12 porque existen 12 atributos de entrada\n","          # Esta capa de entrada se mantiene siempre\n","          modelNN_Keras.add(layers.Dense(units = 16, activation = 'relu', input_dim = trainX.shape[1]))\n","\n","          # Después añadimos las capas intermedias que correspondan segun el valor del parámetro\n","          for _ in range(capas[capas_ind]):\n","            modelNN_Keras.add(layers.Dense(units = 6, activation = 'relu'))\n","\n","          # La capa de salida se mantiene siempre y tiene como función de activación sigmoid\n","          modelNN_Keras.add(layers.Dense(units = 1, activation = 'sigmoid'))\n","          modelNN_Keras.summary()\n","\n","          # Para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteración\n","          i=0\n","          acumulador=0\n","\n","          # Repetimos 3 veces para cada modelo con su combinación de parámetros el proceso de entrenamiento y predicción\n","          for i in range(3):\n","              # Se ajusta el optimizador y la función de pérdida\n","              modelNN_Keras.compile(optimizer=optimizer, loss=funciones_perdidas[perdida_ind], metrics=['accuracy'])\n","              # Se ajustan las épocas y el batch_size\n","              history = modelNN_Keras.fit(trainX_reduced, trainY_reduced, validation_split = 0.1, epochs=epocas[epoca_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n","              # Se realiza predicción\n","              y_pred = modelNN_Keras.predict(testX_reduced)\n","              # Evalua RMSE y acumula su valor\n","              rmse = math.sqrt(mean_squared_error(testY_reduced, y_pred))\n","              acumulador=acumulador+rmse\n","              print(\"Ejecucción: \",str(i))\n","\n","          # Calcula la media de RMSE en las 3 iteraciones\n","          media=acumulador/3\n","          print(\"Media: \",str(media))\n","          # Se almacena en el dataframe junto a los parámetros seleccionados\n","          dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(capas[capas_ind]),str(funciones_perdidas[perdida_ind]),str(batch_sizes[batch_ind]),str(epocas[epoca_ind]), media]\n","          print(\"Completado parámetros\\n\\n\")\n","\n","\n","print(dfError)\n","dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/MLP_resultados.csv\", index=False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8SFhQ8cZkcc3"},"source":["<h1>Preparación de los datos para LSTM</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vyWBJsqCkcc4"},"outputs":[],"source":["# Convertimos los datos en un formato adecuado para LSTM\n","trainX, trainY = CreaDatos(train, Historia)\n","testX, testY   = CreaDatos(test, Historia)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvdhlGvCkcc4"},"outputs":[],"source":["print(trainX.shape)\n","print(trainY.shape)\n","print(testX.shape)\n","print(testY.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TciPBbSmJdNz"},"outputs":[],"source":["trainX_reduced=trainX[:50]\n","trainY_reduced=trainY[:50]\n","testX_reduced=testX[:20]\n","testY_reduced=testY[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiExIC9kJi1x"},"outputs":[],"source":["print(trainX_reduced.shape)\n","print(trainY_reduced.shape)\n","print(testX_reduced.shape)\n","print(testY_reduced.shape)"]},{"cell_type":"markdown","metadata":{"id":"axik_-S6kcc5"},"source":["<h1>LSTM para un problema de regresion</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GUJMzjdkcc5"},"outputs":[],"source":["\n","# Dataframe para almacenar el RMSE con las diferentes combinaciones de parámetros\n","dfError = pd.DataFrame(columns=[\"func_salida\",\"LSTM_dim\",\"batch\",\"epoca\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","func_salida=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n","batch_sizes=[16,32,64]\n","epocas=[6,10,14]\n","LSTM_dim=[4,8,12,16]\n","\n","func_salida_ind=0\n","batch_ind=0\n","epocas_ind=0\n","LSTM_dim_ind=0\n","\n","# Recorrer parámetros\n","for func_salida_ind in range(len(func_salida)):\n","  for batch_ind in range(len(batch_sizes)):\n","    for epocas_ind in range(len(epocas)):\n","      for LSTM_dim_ind in range(len(LSTM_dim)):\n","\n","        # Imprimir valores valuados\n","        print(\"\\n\\n\\n\")\n","        print(\"func_salida:\",str(func_salida_ind))\n","        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n","        print(\"batch:\",str(batch_ind))\n","        print(\"epoca:\",str(epocas_ind))\n","        # Ajustar los parámetros para cuando vaya a hacer la predicción en la función CalculoRMSE\n","        BATCHSIZE=batch_sizes[batch_ind]\n","        EPOCAS=epocas[epocas_ind]\n","        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n","\n","        # Crear el modelo\n","        model = Sequential()\n","        # Ajustar parámetro lstm_dim\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape[1],trainX.shape[2])))\n","        # Ajustar parámetro función de salida\n","        model.add(Dense(1, activation=func_salida[func_salida_ind]))\n","        model.compile(loss='mean_squared_error', optimizer='adam')\n","        model.summary()\n","\n","        # Para realizar las 3 iteraciones y acumular el RMSE de cada iteración\n","        i=0\n","        acumulador=0\n","\n","        # Realizar 3 veces con el modelo el entrenamiento\n","        for i in range(3):\n","\n","            # Ajustar el batch_size y el número de épocas\n","            model.fit(trainX, trainY[:,13], epochs=epocas[epocas_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n","\n","            # Se llama a la función que obtiene el RMSE y realiza la gráfica para comparar los valores reales con los predichos\n","            testScore=CalculoRMSE (\"LSTM-vainilla\")\n","            acumulador=acumulador+testScore\n","            print(\"Ejecucción: \",str(i))\n","\n","        # Calcular la media de RMSE en las 3 iteraciones\n","        media=acumulador/3\n","        print(\"media: \",str(media))\n","        # Se almacena en el dataframe junto a los parámetros seleccionados\n","        dfError.loc[len(dfError)] = [str(func_salida[func_salida_ind]),str(LSTM_dim[LSTM_dim_ind]),str(batch_sizes[batch_ind]),str(epocas[epocas_ind]), media]\n","        print(\"Completado parámetros\\n\\n\")\n","\n","# Guardar el dataframe\n","print(dfError)\n","dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/LSTM_1_resultados.csv\", index=False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QUXHTjZ6kcc5"},"source":["<h1>LSTM utilizando una ventana temporal</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZt6XaCekcc5"},"outputs":[],"source":["# Convertir los datos en un formato adecuado para LSTM\n","Historia = 3\n","trainX, trainY = CreaDatos (train, Historia)\n","testX, testY   = CreaDatos (test, Historia)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjXY4DKuL04W"},"outputs":[],"source":["print(trainX.shape)\n","print(trainY.shape)\n","print(testX.shape)\n","print(testY.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjR2tthUkcc5"},"outputs":[],"source":["\n","# Dataframe para almacenar las combinaciones de parámetros y su RMSE medio obtenido en las 3 iteraciones\n","dfError = pd.DataFrame(columns=[\"opt\",\"LSTM_dim\",\"perdida\",\"epoca\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","optimizadores=[\"SGD\",\"adam\",\"RMSprop\"]\n","funciones_perdidas=[\"mean_squared_error\",\"mean_absolute_error\",\"huber_loss\"]\n","epocas=[6,10,14]\n","LSTM_dim=[2,5,10]\n","\n","\n","\n","LSTM_dim_ind=0\n","perdida_ind=0\n","epoca_ind=0\n","opt_ind=0\n","\n","# Recorrer parametros\n","for LSTM_dim_ind in range(len(LSTM_dim)):\n","  for perdida_ind in range(len(funciones_perdidas)):\n","    for epoca_ind in range(len(epocas)):\n","        for opt_ind in range(len(optimizadores)):\n","\n","          # Imprimir por donde llega\n","          print(\"\\n\\n\\n\")\n","          print(\"LSTM_dim:\",str(LSTM_dim_ind))\n","          print(\"perdida:\",str(perdida_ind))\n","          print(\"epoca:\",str(epoca_ind))\n","          print(\"opt:\",str(opt_ind))\n","          # Ajustar los parámetros para cuando vaya a hacer la predicción en la función CalculoRMSE\n","          BATCHSIZE=1\n","          EPOCAS=epocas[epoca_ind]\n","          LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n","\n","          # Establecer el optimizador\n","          optimizer=None\n","          if(optimizadores[opt_ind]==\"SGD\"):\n","            optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n","            print(\"SGD\")\n","          if(optimizadores[opt_ind]==\"adam\"):\n","            optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","            print(\"Adam\")\n","          if(optimizadores[opt_ind]==\"RMSprop\"):\n","            optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n","            print(\"RMSprop\")\n","\n","          # Crear el modelo\n","          model = Sequential()\n","          # Ajustar parámetro LSTM_dim\n","          model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape [1], trainX.shape[2])))\n","          model.add(Dense(1, activation='sigmoid'))\n","          # Ajustar optimizador y función de perdida\n","          model.compile(loss=funciones_perdidas[perdida_ind], optimizer=optimizer)\n","\n","          # Para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteración\n","          i=0\n","          acumulador=0\n","\n","          for i in range(3):\n","              # Entrenar el modelo y ajustar épocas\n","              model.fit(trainX, trainY[:,13], epochs=epocas[epoca_ind], batch_size=1, verbose=0)\n","\n","              # llamar a la función que obtiene el RMSE y realiza la gráfica para comparar los valores reales con los predichos\n","              testScore=CalculoRMSE (\"LSTM-vainilla\")\n","              acumulador=acumulador+testScore\n","              print(\"ejecuccion: \",str(i))\n","\n","          # Calcular la media de RMSE en las 3 iteraciones\n","          media=acumulador/3\n","          print(\"media: \",str(media))\n","          # Almacenarlo en el dataframe junto a los parámetros seleccionados\n","          dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(LSTM_dim[LSTM_dim_ind]),str(funciones_perdidas[perdida_ind]),str(epocas[epoca_ind]), media]\n","          print([str(optimizadores[opt_ind]),str(LSTM_dim[LSTM_dim_ind]),str(funciones_perdidas[perdida_ind]),str(epocas[epoca_ind]), media])\n","          print(\"Completado parámetros\\n\\n\")\n","\n","          # Guardar el dataframe\n","          print(dfError)\n","          dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/LSTM_2_resultados.csv\", index=False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JwdWZB_8kcc5"},"source":["<h1>LSTM apiladas</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNFGtqGfkcc5"},"outputs":[],"source":["# Convertir los datos en un formato adecuado para LSTM\n","historia = 1\n","trainX, trainY = CreaDatos (train, historia)\n","testX, testY   = CreaDatos (test, historia)\n","\n","print (trainX.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bc1zj2B9kcc6"},"outputs":[],"source":["# Dataframe para almacenar el RMSE con las diferentes combinaciones de parámetros\n","dfError = pd.DataFrame(columns=[\"opt\",\"batch\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","optimizadores=[\"RMSprop\",\"adam\",\"SGD\"]\n","batch_sizes=[16,32,64]\n","epocas=[6,10,14]\n","LSTM_dim=[4,8,12]\n","\n","\n","func_perdida_ind=0\n","batch_ind=0\n","epocas_ind=0\n","LSTM_dim_ind=0\n","opt_ind=0\n","\n","# Recorrer parámetros\n","for batch_ind in range(len(batch_sizes)):\n","  for epocas_ind in range(len(epocas)):\n","    for LSTM_dim_ind in range(len(LSTM_dim)):\n","      for opt_ind in range(len(optimizadores)):\n","\n","        # Imprimir por donde llega\n","        print(\"\\n\\n\\n\")\n","        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n","        print(\"batch:\",str(batch_ind))\n","        print(\"epoca:\",str(epocas_ind))\n","        print(\"optimizador:\",str(opt_ind))\n","        # Ajustar los parámetros para cuando vaya a hacer la predicción en la función CalculoRMSE\n","        BATCHSIZE=batch_sizes[batch_ind]\n","        EPOCAS=epocas[epocas_ind]\n","        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n","\n","\n","        # Establecer el optimizador\n","        optimizer=None\n","        if(optimizadores[opt_ind]==\"SGD\"):\n","          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n","          print(\"SGD\")\n","        if(optimizadores[opt_ind]==\"adam\"):\n","          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","          print(\"Adam\")\n","        if(optimizadores[opt_ind]==\"RMSprop\"):\n","          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n","          print(\"RMSprop\")\n","\n","\n","\n","        # Crear el modelo y entrenar\n","        model = Sequential()\n","        # Ajustar parámetro LSTM_Dim\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape[1],trainX.shape[2]), return_sequences=True))\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind]))\n","        model.add(Dense(1, activation='sigmoid'))\n","        # Ajustar optimizador y función de pérdida\n","        model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n","\n","\n","        # Para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteración\n","        i=0\n","        acumulador=0\n","\n","        # Entrenar modelo 3 veces\n","        for i in range(3):\n","            # Ajustar épocas y batch size\n","            model.fit(trainX, trainY[:,13], epochs=epocas[epocas_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n","            # Llamar a la función que obtiene el RMSE y realiza la gráfica para comparar los valores reales con los predichos\n","            testScore=CalculoRMSE (\"LSTM-dos capas\")\n","            acumulador=acumulador+testScore\n","            print(\"ejecuccion: \",str(i))\n","\n","        # Calcular la media de RMSE en las 3 iteraciones\n","        media=acumulador/3\n","        print(\"media: \",str(media))\n","        # Lo almacena en el dataframe junto a los parámetros seleccionados\n","        dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(batch_sizes[batch_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n","        print(\"completado parametros\\n\\n\")\n","\n","        # Guardar el dataframe\n","        print(dfError)\n","        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/LSTM_3_resultados.csv\", index=False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dEFisDC3kcc6"},"source":["<h1>LSTM con memoria entre lote y lote</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqchrJgAkcc6"},"outputs":[],"source":["# Dataframe para almacenar el RMSE con las diferentes combinaciones de parámetros\n","dfError = pd.DataFrame(columns=[\"func_act\",\"opt\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","func_activacion=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n","optimizadores=[\"RMSprop\",\"SGD\",\"adam\"]\n","epocas=[6,10,14]\n","LSTM_dim=[4,8,12]\n","\n","\n","\n","# Recorrer parámetros\n","for func_activacion_ind in range(len(func_activacion)):\n","  for opt_ind in range(len(optimizadores)):\n","    for epocas_ind in range(len(epocas)):\n","      for LSTM_dim_ind in range(len(LSTM_dim)):\n","\n","        # Imprimir por donde llega\n","        print(\"\\n\\n\\n\")\n","        print(\"func_acticacion:\",str(func_activacion_ind))\n","        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n","        print(\"optimizador:\",str(opt_ind))\n","        print(\"epoca:\",str(epocas_ind))\n","        # Ajustar los parámetros para cuando vaya a hacer la predicción en la función CalculoRMSE\n","        BATCHSIZE=1\n","        EPOCAS=epocas[epocas_ind]\n","        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n","\n","        # Establecer el optimizador\n","        optimizer=None\n","        if(optimizadores[opt_ind]==\"SGD\"):\n","          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n","          print(\"SGD\")\n","        if(optimizadores[opt_ind]==\"adam\"):\n","          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","          print(\"Adam\")\n","        if(optimizadores[opt_ind]==\"RMSprop\"):\n","          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n","          print(\"RMSprop\")\n","\n","\n","\n","        # Crear el modelo y entrenar\n","        batch_size_alterado = 1\n","        model = Sequential()\n","        # Ajustar parámetro LSTM_dim\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape [1], trainX.shape [2]), stateful=True))\n","        # Después se añaden las capas intermedias que correspondan segun el valor del parámetro\n","\n","        # Capa de salida se mantiene\n","        model.add(Dense(1, activation=func_activacion[func_activacion_ind]))\n","        # Ajustar optimizador\n","        model.compile(loss='mean_squared_error', optimizer=optimizer)\n","\n","        # Para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteración\n","        i=0\n","        acumulador=0\n","        k=0\n","\n","        # Repetir 3 veces el entrenamiento\n","        for i in range(3):\n","            # En este modelo, se realizan tantas iteraciones como épocas\n","            for k in range(epocas[epocas_ind]):\n","                # Ajustar el parámetro de batch\n","                model.fit(trainX, trainY[:,13], epochs=1, batch_size=1, verbose=0, shuffle=False)\n","\n","                # Llamar a la función que obtiene el RMSE y realiza la gráfica para comparar los valores reales con los predichos\n","                testScore=CalculoRMSE(\"LSTM - con memoria entre lote y lote\")\n","                acumulador=acumulador+testScore\n","                print(\"ejecuccion: \",str(i))\n","\n","                model.reset_states()\n","\n","\n","        # Calcular la media de RMSE en las 3 iteraciones\n","        media=acumulador/3\n","        print(\"media: \",str(media))\n","        #Lo almacena en el dataframe junto a los parámetros seleccionados\n","        dfError.loc[len(dfError)] = [str(func_activacion[func_activacion_ind]),str(optimizadores[opt_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n","        print(\"Completado parámetros\\n\\n\")\n","\n","        # Guardar el dataframe\n","        print(dfError)\n","        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/LSTM_4_resultados.csv\", index=False)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5vOLd9K6kcc6"},"source":["<h1>LSTM's apilados (varias capas) con memoria entre lote y lote</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2k0vKMMkcc6","tags":[]},"outputs":[],"source":["\n","# Dataframe para almacenar el RMSE con las diferentes combinaciones de parámetros\n","dfError = pd.DataFrame(columns=[\"func_activacion\",\"opt\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n","\n","# Parámetros a evaluar y sus valores diferentes\n","func_activacion=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n","optimizadores=[\"RMSprop\",\"SGD\",\"adam\"]\n","epocas=[6,10,14]\n","LSTM_dim=[4,8,12,16]\n","\n","\n","\n","# Recorrer parámetros\n","for func_activacion_ind in range(len(func_activacion)):\n","  for opt_ind in range(len(optimizadores)):\n","    for epocas_ind in range(len(epocas)):\n","      for LSTM_dim_ind in range(len(LSTM_dim)):\n","\n","        # Imprimir por donde llega\n","        print(\"\\n\\n\\n\")\n","        print(\"func_activacion:\",str(func_activacion_ind))\n","        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n","        print(\"optimizador:\",str(opt_ind))\n","        print(\"epoca:\",str(epocas_ind))\n","        # Ajustar los parámetros para cuando vaya a hacer la predicción en la función CalculoRMSE\n","        BATCHSIZE=1\n","        EPOCAS=epocas[epocas_ind]\n","        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n","\n","        # Establecer el optimizador\n","        optimizer=None\n","        if(optimizadores[opt_ind]==\"SGD\"):\n","          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n","          print(\"SGD\")\n","        if(optimizadores[opt_ind]==\"adam\"):\n","          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","          print(\"Adam\")\n","        if(optimizadores[opt_ind]==\"RMSprop\"):\n","          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n","          print(\"RMSprop\")\n","\n","        # Crear el modelo y entrenar\n","        batch_size_alterado = 1\n","        model = Sequential()\n","        # Ajustar parámetro LSTM_dim\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape[1], trainX.shape[2]), stateful=True, return_sequences=True))\n","        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape[1], trainX.shape[2]), stateful=True))\n","        # Ajustar parámetro función activación salida\n","        model.add(Dense(1, activation=func_activacion[func_activacion_ind]))\n","        model.compile(loss='mean_squared_error', optimizer=optimizer)\n","\n","        # Para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteración\n","        i=0\n","        acumulador=0\n","        k=0\n","\n","        # Repetir 3 veces el entreno\n","        for i in range(3):\n","            # Recorrer bucle tantas épocas se tengan\n","            for k in range(epocas[epocas_ind]):\n","                # Ajustar parámetro batch_size\n","                model.fit(trainX, trainY[:,13], epochs=1, batch_size=BATCHSIZE, verbose=0, shuffle=False)\n","                # Llamar a la función que obtiene el RMSE y realiza la gráfica para comparar los valores reales con los predichos\n","                testScore=CalculoRMSE(\"prueba\")\n","                acumulador=acumulador+testScore\n","                print(\"ejecuccion: \",str(i))\n","\n","                model.reset_states()\n","\n","\n","        # Calcular la media de RMSE en las 3 iteraciones\n","        media=acumulador/3\n","        print(\"media: \",str(media))\n","        # Lo almacena en el dataframe junto a los parámetros seleccionados\n","        dfError.loc[len(dfError)] = [str(func_activacion[func_activacion_ind]),str(optimizadores[opt_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n","        print(\"Completado parámetros\\n\\n\")\n","\n","        # Guardar el dataframe\n","        print(dfError)\n","        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/proyecto-tensorflow/buenos/LSTM_5_resultados.csv\", index=False)\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"8e5e9526956f0969fe605d41ae39091028f4f1b8fb42028371b20ef3bd5381d3"}}},"nbformat":4,"nbformat_minor":0}
